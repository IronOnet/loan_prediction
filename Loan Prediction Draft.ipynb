{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "588af781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f6c966b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = './data/d_training_set.csv' \n",
    "test_data_path = './data/d_test_set.csv' \n",
    "\n",
    "train_data = pd.read_csv(train_data_path) \n",
    "test_data = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3b24d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(dframe, test=None):\n",
    "    df = dframe\n",
    "    print('Data Processing Started')\n",
    "    if not test: \n",
    "        df= df.drop('row_id', axis=1)\n",
    "        #X, y = df.loc[:, df.columns != 'repaid_loan'], df['repaid_loan'] \n",
    "        cat_features = (df.dtypes == 'object') \n",
    "        cat_features = list(cat_features[cat_features].index) \n",
    "        num_features = (df.dtypes != 'object') \n",
    "        num_features = list(num_features[num_features].index) \n",
    "\n",
    "        df_cat = df[cat_features] \n",
    "        df_num  = df[num_features] \n",
    "\n",
    "        df_cat.fillna('Unknown', axis=1, inplace=True)\n",
    "        # Additional numerical features in the dataset \n",
    "        num_features_2 = ['term', 'int_rate', 'emp_length', 'issue_d', 'revol_util'] \n",
    "\n",
    "        # Replacing the percentage symbol with an empty string \n",
    "        df_cat['int_rate'] = df_cat['int_rate'].replace({'%': ''}, regex=True) \n",
    "        # convert the string to a float \n",
    "        df_cat['int_rate'] = df_cat['int_rate'].astype(float) \n",
    "        # Replacing string symbols with integers \n",
    "        df_cat['term'] = df_cat['term'].replace({' 36 months': 36, ' 60 months': 60}, regex=True)\n",
    "        df_cat['emp_length'] = df_cat['emp_length'].replace({'years': '', '10+': 10, 'year': '', '< 1 year': 1}, regex=True)\n",
    "        # drop the 'issue_d' column as we deem it unnecessary for the model \n",
    "        df_cat.drop('issue_d', axis=1, inplace=True)\n",
    "        df_cat['revol_util'] = df_cat['revol_util'].replace({'%': ''}, regex=True) \n",
    "        df_cat['revol_util'] = df_cat['revol_util'].replace({'Unknown': 0}, regex=True)\n",
    "        df_cat['revol_util'] = df_cat['revol_util'].astype(float) \n",
    "        df_cat['term'] = df_cat['term'].astype(float)\n",
    "        num_features_2.remove('issue_d')\n",
    "\n",
    "        df_num_2 = df_cat[num_features_2] \n",
    "        df_num = pd.concat([df_num, df_num_2], axis=1)\n",
    "        # Filling missing variables with the mean of each column \n",
    "        df_num.fillna(df_num.mean(), inplace=True) \n",
    "        # drop the new numeric features from the categorical dataframe\n",
    "        df_cat = df_cat.drop(num_features_2, axis=1)\n",
    "\n",
    "        df_num['emp_length'] = df_num['emp_length'].replace({'< 1': 1}, regex=True) \n",
    "        df_num = df_num.replace({'Unknown': 0}, regex=True)\n",
    "\n",
    "        df_combined = pd.concat([df_num, df_cat], axis=1)\n",
    "        # categorical features (or attributes) \n",
    "        cat_attribs = list(df_cat.columns) \n",
    "        num_attribs = list(df_num.columns) \n",
    "        if 'repaid_loan' in num_attribs:\n",
    "            num_attribs.remove('repaid_loan')\n",
    "        print('*************Training data processed!!*************')\n",
    "        return df_combined, cat_attribs, num_attribs\n",
    "\n",
    "    elif test: \n",
    "        # if it's the test set \n",
    "        if 'row_id' in list(df.columns):\n",
    "            \n",
    "            test_row_id = df[['row_id']].copy() \n",
    "            df=df.drop('row_id', axis=1)\n",
    "        cat_features = (df.dtypes == 'object') \n",
    "        cat_features = list(cat_features[cat_features].index) \n",
    "        num_features = (df.dtypes != 'object') \n",
    "        num_features = list(num_features[num_features].index) \n",
    "\n",
    "        df_cat = df[cat_features] \n",
    "        df_num  = df[num_features] \n",
    "\n",
    "        df_cat.fillna('Unknown', axis=1, inplace=True)\n",
    "        # Additional numerical features in the dataset \n",
    "        num_features_2 = ['term', 'int_rate', 'emp_length', 'issue_d', 'revol_util'] \n",
    "\n",
    "        # Replacing the percentage symbol with an empty string \n",
    "        df_cat['int_rate'] = df_cat['int_rate'].replace({'%': ''}, regex=True) \n",
    "        # convert the string to a float \n",
    "        df_cat['int_rate'] = df_cat['int_rate'].astype(float) \n",
    "        # Replacing string symbols with integers \n",
    "        df_cat['term'] = df_cat['term'].replace({' 36 months': 36, ' 60 months': 60}, regex=True)\n",
    "        df_cat['emp_length'] = df_cat['emp_length'].replace({'years': '', '10+': 10, 'year': '', '< 1 year': 1}, regex=True)\n",
    "        # drop the 'issue_d' column as we deem it unnecessary for the model \n",
    "        df_cat.drop('issue_d', axis=1, inplace=True)\n",
    "        df_cat['revol_util'] = df_cat['revol_util'].replace({'%': ''}, regex=True) \n",
    "        df_cat['revol_util'] = df_cat['revol_util'].replace({'Unknown': 0}, regex=True)\n",
    "        df_cat['revol_util'] = df_cat['revol_util'].astype(float) \n",
    "        df_cat['term'] = df_cat['term'].astype(float)\n",
    "        num_features_2.remove('issue_d')\n",
    "\n",
    "        df_num_2 = df_cat[num_features_2] \n",
    "        df_num = pd.concat([df_num, df_num_2], axis=1)\n",
    "        # Filling missing variables with the mean of each column \n",
    "        df_num.fillna(df_num.mean(), inplace=True) \n",
    "        # drop the new numeric features from the categorical dataframe\n",
    "        df_cat = df_cat.drop(num_features_2, axis=1)\n",
    "\n",
    "        df_num['emp_length'] = df_num['emp_length'].replace({'< 1': 1}, regex=True) \n",
    "        df_num = df_num.replace({'Unknown': 0}, regex=True)\n",
    "\n",
    "        df_combined = pd.concat([df_num, df_cat], axis=1)\n",
    "        # categorical features (or attributes) \n",
    "        cat_attribs = list(df_cat.columns) \n",
    "        num_attribs = list(df_num.columns) \n",
    "        print('*************Test data processed!!***************')\n",
    "        return df_combined, cat_attribs, num_attribs, test_row_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed3d40e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103887, 93)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18f80737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 92)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caed216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat_data = pd.concat([train_data, test_data], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57eb8a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Processing Started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iron_onet/Documents/Courses/algotrade/venv/lib/python3.8/site-packages/pandas/core/frame.py:5171: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().fillna(\n",
      "/tmp/ipykernel_22610/4000799705.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cat['int_rate'] = df_cat['int_rate'].replace({'%': ''}, regex=True)\n",
      "/tmp/ipykernel_22610/4000799705.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cat['int_rate'] = df_cat['int_rate'].astype(float)\n",
      "/tmp/ipykernel_22610/4000799705.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cat['term'] = df_cat['term'].replace({' 36 months': 36, ' 60 months': 60}, regex=True)\n",
      "/tmp/ipykernel_22610/4000799705.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cat['emp_length'] = df_cat['emp_length'].replace({'years': '', '10+': 10, 'year': '', '< 1 year': 1}, regex=True)\n",
      "/home/iron_onet/Documents/Courses/algotrade/venv/lib/python3.8/site-packages/pandas/core/frame.py:4901: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "/tmp/ipykernel_22610/4000799705.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cat['revol_util'] = df_cat['revol_util'].replace({'%': ''}, regex=True)\n",
      "/tmp/ipykernel_22610/4000799705.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cat['revol_util'] = df_cat['revol_util'].replace({'Unknown': 0}, regex=True)\n",
      "/tmp/ipykernel_22610/4000799705.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cat['revol_util'] = df_cat['revol_util'].astype(float)\n",
      "/tmp/ipykernel_22610/4000799705.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cat['term'] = df_cat['term'].astype(float)\n",
      "/tmp/ipykernel_22610/4000799705.py:37: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_num.fillna(df_num.mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************Training data processed!!*************\n"
     ]
    }
   ],
   "source": [
    "X_train_proc, cat_attribs, num_attribs = process_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33d8b4f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'repaid_loan' in num_attribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dd24f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num, y_train = X_train_proc[num_attribs], X_train_proc['repaid_loan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5921ad0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Processing Started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22610/4000799705.py:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cat['int_rate'] = df_cat['int_rate'].replace({'%': ''}, regex=True)\n",
      "/tmp/ipykernel_22610/4000799705.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cat['int_rate'] = df_cat['int_rate'].astype(float)\n",
      "/tmp/ipykernel_22610/4000799705.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cat['term'] = df_cat['term'].replace({' 36 months': 36, ' 60 months': 60}, regex=True)\n",
      "/tmp/ipykernel_22610/4000799705.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cat['emp_length'] = df_cat['emp_length'].replace({'years': '', '10+': 10, 'year': '', '< 1 year': 1}, regex=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************Test data processed!!***************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22610/4000799705.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cat['revol_util'] = df_cat['revol_util'].replace({'%': ''}, regex=True)\n",
      "/tmp/ipykernel_22610/4000799705.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cat['revol_util'] = df_cat['revol_util'].replace({'Unknown': 0}, regex=True)\n",
      "/tmp/ipykernel_22610/4000799705.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cat['revol_util'] = df_cat['revol_util'].astype(float)\n",
      "/tmp/ipykernel_22610/4000799705.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cat['term'] = df_cat['term'].astype(float)\n",
      "/tmp/ipykernel_22610/4000799705.py:89: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_num.fillna(df_num.mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "X_test_proc, _, _, row_id_col = process_data(test_data, test=True)\n",
    "X_test_num = X_test_proc[num_attribs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b499af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08f93f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder \n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('num' , num_pipeline, num_attribs), \n",
    "\n",
    "])\n",
    "\n",
    "train_data_prepared = full_pipeline.fit_transform(X_train_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "865aaeb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103887, 77)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_prepared.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23dfd362",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_prepared = full_pipeline.fit_transform(X_test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "767626c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 77)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_prepared.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "304604c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression \n",
    "\n",
    "lin_reg = LinearRegression() \n",
    "lin_reg.fit(train_data_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e52c128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  [0.94908992 0.96364431 0.80458191 0.85238397 0.76896628]\n"
     ]
    }
   ],
   "source": [
    "some_data = X_train_num.iloc[:5] \n",
    "some_labels = y_train.iloc[:5] \n",
    "some_data_prepared = full_pipeline.transform(some_data) \n",
    "\n",
    "print(\"Predictions: \", lin_reg.predict(some_data_prepared))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "785161d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3687883993837638"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "loan_predictions = lin_reg.predict(train_data_prepared) \n",
    "lin_mse = mean_squared_error(y_train, loan_predictions) \n",
    "lin_rmse = np.sqrt(lin_mse) \n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d6422f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27378774773857867"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error \n",
    "\n",
    "lin_mae = mean_absolute_error(y_train, loan_predictions) \n",
    "lin_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0eac91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(random_state=42)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor \n",
    "\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "tree_reg.fit(train_data_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e49f9760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_predictions = tree_reg.predict(train_data_prepared) \n",
    "tree_mse = mean_squared_error(y_train, loan_predictions) \n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8227da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [0.5296121  0.52924848 0.53449676 0.52979382 0.53278319 0.52605609\n",
      " 0.52523205 0.53470255 0.52672147 0.52708686]\n",
      "Mean:  0.5295733367662984\n",
      "STD:  0.0032640649660648233\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score \n",
    "\n",
    "scores = cross_val_score(tree_reg, train_data_prepared, y_train, scoring=\"neg_mean_squared_error\", cv=10) \n",
    "tree_rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores: \", scores) \n",
    "    print(\"Mean: \", scores.mean()) \n",
    "    print(\"STD: \", scores.std()) \n",
    "    \n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d52dc52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=10, random_state=42)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor \n",
    "\n",
    "forest_reg = RandomForestRegressor(n_estimators=10, random_state=42) \n",
    "forest_reg.fit(train_data_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42f0e07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16508942100281815"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_reg_predictions = forest_reg.predict(train_data_prepared) \n",
    "forest_mse = mean_squared_error(y_train, forest_reg_predictions) \n",
    "forest_rmse = np.sqrt(forest_mse) \n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7aa5ca3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [0.38538364 0.39301706 0.39430077 0.3905664  0.39116851 0.39145385\n",
      " 0.39050108 0.39465406 0.39210784 0.39309353]\n",
      "Mean:  0.39162467453940353\n",
      "STD:  0.0024947662940969072\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score \n",
    "\n",
    "forest_scores = cross_val_score(forest_reg, train_data_prepared, y_train, \n",
    "                               scoring=\"neg_mean_squared_error\", cv=10) \n",
    "forest_rmse_scores = np.sqrt(-forest_scores) \n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99bb91ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(random_state=42),\n",
       "             param_grid=[{'max_features': [2, 4, 6, 8],\n",
       "                          'n_estimators': [3, 10, 30]},\n",
       "                         {'bootstrap': [False], 'max_features': [2, 3, 4],\n",
       "                          'n_estimators': [3, 10]}],\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "\n",
    "param_grid = [\n",
    "    # try 12 (3x4) combinations of hyperparameters \n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]}, \n",
    "    {'bootstrap' : [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]}\n",
    "]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42) \n",
    "# train accross 5 folds, that's a total of (12+6)*5=90 rounds of training \n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5, \n",
    "                          scoring='neg_mean_squared_error', return_train_score=True) \n",
    "grid_search.fit(train_data_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6afc58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 8, 'n_estimators': 30}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d49b7925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features=8, n_estimators=30, random_state=42)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89eb8a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.432061543336738 {'max_features': 2, 'n_estimators': 3}\n",
      "0.38906241953925563 {'max_features': 2, 'n_estimators': 10}\n",
      "0.3767310916463088 {'max_features': 2, 'n_estimators': 30}\n",
      "0.4302146738012032 {'max_features': 4, 'n_estimators': 3}\n",
      "0.3890718173181303 {'max_features': 4, 'n_estimators': 10}\n",
      "0.37615580586403147 {'max_features': 4, 'n_estimators': 30}\n",
      "0.4305501526654589 {'max_features': 6, 'n_estimators': 3}\n",
      "0.3891503531781742 {'max_features': 6, 'n_estimators': 10}\n",
      "0.37617664295804354 {'max_features': 6, 'n_estimators': 30}\n",
      "0.43076492991936877 {'max_features': 8, 'n_estimators': 3}\n",
      "0.38902169140716103 {'max_features': 8, 'n_estimators': 10}\n",
      "0.37614317295857935 {'max_features': 8, 'n_estimators': 30}\n",
      "0.4295615588557637 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n",
      "0.38886504889365825 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n",
      "0.4305141019121064 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n",
      "0.38835974222037983 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
      "0.429484382513413 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n",
      "0.38791533432379954 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "# cross validation results \n",
    "cvres = grid_search.cv_results_ \n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]): \n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "979b0978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(random_state=42),\n",
       "                   param_distributions={'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f89b3dab2b0>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f89b3f06f70>},\n",
       "                   random_state=42, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "from scipy.stats import randint \n",
    "\n",
    "param_distribs = {\n",
    "    'n_estimators': randint(low=1, high=200), \n",
    "    'max_features': randint(low=1, high=8),\n",
    "}\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42) \n",
    "rnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs, \n",
    "                               n_iter=10, cv=5, scoring=\"neg_mean_squared_error\", random_state=42) \n",
    "rnd_search.fit(train_data_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8b24c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.432061543336738 {'max_features': 2, 'n_estimators': 3}\n",
      "0.38906241953925563 {'max_features': 2, 'n_estimators': 10}\n",
      "0.3767310916463088 {'max_features': 2, 'n_estimators': 30}\n",
      "0.4302146738012032 {'max_features': 4, 'n_estimators': 3}\n",
      "0.3890718173181303 {'max_features': 4, 'n_estimators': 10}\n",
      "0.37615580586403147 {'max_features': 4, 'n_estimators': 30}\n",
      "0.4305501526654589 {'max_features': 6, 'n_estimators': 3}\n",
      "0.3891503531781742 {'max_features': 6, 'n_estimators': 10}\n",
      "0.37617664295804354 {'max_features': 6, 'n_estimators': 30}\n",
      "0.43076492991936877 {'max_features': 8, 'n_estimators': 3}\n",
      "0.38902169140716103 {'max_features': 8, 'n_estimators': 10}\n",
      "0.37614317295857935 {'max_features': 8, 'n_estimators': 30}\n",
      "0.4295615588557637 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n",
      "0.38886504889365825 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n",
      "0.4305141019121064 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n",
      "0.38835974222037983 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
      "0.429484382513413 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n",
      "0.38791533432379954 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "cv_res = rnd_search.cv_results_ \n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]): \n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f55febc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b0aebac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01568481, 0.01588435, 0.01625727, 0.02243768, 0.02269805,\n",
       "       0.025423  , 0.00383759, 0.00650887, 0.01420588, 0.00982911,\n",
       "       0.0118139 , 0.00326612, 0.0201668 , 0.01689525, 0.00129296,\n",
       "       0.01068757, 0.00144675, 0.00150919, 0.00028023, 0.00721264,\n",
       "       0.02159454, 0.0075509 , 0.0093202 , 0.00601035, 0.00847495,\n",
       "       0.01839686, 0.01736784, 0.01921478, 0.00660651, 0.01123777,\n",
       "       0.02250359, 0.01958563, 0.02152768, 0.00869568, 0.00914581,\n",
       "       0.01134226, 0.01570578, 0.02314643, 0.02344096, 0.02126301,\n",
       "       0.00059958, 0.00052399, 0.02259178, 0.02400982, 0.01564781,\n",
       "       0.01355856, 0.00836929, 0.01804774, 0.00917342, 0.01506943,\n",
       "       0.01100826, 0.00475165, 0.01017774, 0.01141671, 0.01102994,\n",
       "       0.01371695, 0.01494235, 0.01193035, 0.01530799, 0.01110247,\n",
       "       0.01255239, 0.00141829, 0.00018546, 0.00184773, 0.00942744,\n",
       "       0.01277804, 0.01130618, 0.00247469, 0.00181903, 0.02255386,\n",
       "       0.01931955, 0.02256703, 0.01774655, 0.00515072, 0.05298947,\n",
       "       0.01139059, 0.02202754])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "26e99946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40efe67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tree_model = grid_search.best_estimator_ \n",
    "final_test_predictions = final_tree_model.predict(X_test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "76297129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.4       , 0.4       , ..., 0.43333333, 0.36666667,\n",
       "       0.5       ])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3132abfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iron_onet/Documents/Courses/algotrade/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(batch_size=103887, learning_rate_init=0.01, max_iter=100,\n",
       "             momentum=0.04, random_state=42, solver='sgd')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor \n",
    "\n",
    "\n",
    "mlp = MLPRegressor(solver='sgd', max_iter=100, activation='relu', \n",
    "                  random_state=42, learning_rate_init=0.01, \n",
    "                  batch_size=train_data_prepared.shape[0], momentum= 0.04)\n",
    "mlp.fit(train_data_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "46056a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iron_onet/Documents/Courses/algotrade/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:542: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\"Got `batch_size` less than 1 or larger than \"\n",
      "/home/iron_onet/Documents/Courses/algotrade/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/iron_onet/Documents/Courses/algotrade/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:542: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\"Got `batch_size` less than 1 or larger than \"\n",
      "/home/iron_onet/Documents/Courses/algotrade/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/iron_onet/Documents/Courses/algotrade/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:542: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\"Got `batch_size` less than 1 or larger than \"\n",
      "/home/iron_onet/Documents/Courses/algotrade/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/iron_onet/Documents/Courses/algotrade/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:542: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\"Got `batch_size` less than 1 or larger than \"\n",
      "/home/iron_onet/Documents/Courses/algotrade/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/iron_onet/Documents/Courses/algotrade/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:542: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\"Got `batch_size` less than 1 or larger than \"\n",
      "/home/iron_onet/Documents/Courses/algotrade/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/iron_onet/Documents/Courses/algotrade/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:542: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\"Got `batch_size` less than 1 or larger than \"\n",
      "/home/iron_onet/Documents/Courses/algotrade/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/iron_onet/Documents/Courses/algotrade/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:542: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\"Got `batch_size` less than 1 or larger than \"\n",
      "/home/iron_onet/Documents/Courses/algotrade/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/iron_onet/Documents/Courses/algotrade/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:542: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\"Got `batch_size` less than 1 or larger than \"\n",
      "/home/iron_onet/Documents/Courses/algotrade/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/iron_onet/Documents/Courses/algotrade/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:542: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\"Got `batch_size` less than 1 or larger than \"\n",
      "/home/iron_onet/Documents/Courses/algotrade/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/iron_onet/Documents/Courses/algotrade/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:542: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\"Got `batch_size` less than 1 or larger than \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [0.38538364 0.39301706 0.39430077 0.3905664  0.39116851 0.39145385\n",
      " 0.39050108 0.39465406 0.39210784 0.39309353]\n",
      "Mean:  0.39162467453940353\n",
      "STD:  0.0024947662940969072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iron_onet/Documents/Courses/algotrade/venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp_scores = cross_val_score(mlp, train_data_prepared, y_train, \n",
    "                               scoring=\"neg_mean_squared_error\", cv=10) \n",
    "mlp_rmse_scores = np.sqrt(-forest_scores) \n",
    "display_scores(mlp_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d33fbcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate row_id and repaid_loan columns \n",
    "# save it to a csv file called loan_predictions.csv\n",
    "predictions_pd = pd.DataFrame(final_test_predictions, columns=['repaid_loan'])\n",
    "predictions_csv = pd.concat([row_id_col, predictions_pd], axis=1)\n",
    "predictions_csv.to_csv('loan_predictions.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c617d6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06861467940611984\n"
     ]
    }
   ],
   "source": [
    "# Lets try Boosting algorithms \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.ensemble import AdaBoostRegressor \n",
    "\n",
    "num_trees = 30 \n",
    "kfold = KFold(n_splits=10) \n",
    "model = AdaBoostRegressor(n_estimators=num_trees, random_state=42) \n",
    "results = cross_val_score(model, X_train_num, y_train, cv=kfold) \n",
    "print(results.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536d6a61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
